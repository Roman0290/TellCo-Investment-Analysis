{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/example_notebook.ipynb\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_data_from_postgres, load_data_using_sqlalchemy\n",
    "from sql_queries import execute_telecom_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Fetch database connection parameters from environment variables\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the data\n"
     ]
    }
   ],
   "source": [
    "# Define your SQL query\n",
    "query = \"SELECT * FROM xdr_data;\"\n",
    "\n",
    "# Load data from PostgreSQL using SQLAlchemy\n",
    "df = load_data_using_sqlalchemy(query)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "if df is not None:\n",
    "    print(\"Successfully loaded the data\")\n",
    "else:\n",
    "    print(\"Failed to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values\n",
    "for col in ['Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)', 'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)', 'Handset Type']:\n",
    "    if df[col].dtype == 'object':\n",
    "        # Replace NaN with mode for categorical columns\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    else:\n",
    "        # Replace NaN with mean for numeric columns\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# Aggregate per customer\n",
    "aggregated_experience = df.groupby('MSISDN/Number').agg({\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'mean',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'mean',\n",
    "    'Avg RTT DL (ms)': 'mean',\n",
    "    'Avg RTT UL (ms)': 'mean',\n",
    "    'Avg Bearer TP DL (kbps)': 'mean',\n",
    "    'Avg Bearer TP UL (kbps)': 'mean',\n",
    "    'Handset Type': lambda x: x.mode().iloc[0]  # Handle mode safely\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "aggregated_experience.rename(columns={\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'Avg TCP DL Retransmission',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'Avg TCP UL Retransmission',\n",
    "    'Avg RTT DL (ms)': 'Avg RTT DL',\n",
    "    'Avg RTT UL (ms)': 'Avg RTT UL',\n",
    "    'Avg Bearer TP DL (kbps)': 'Avg Throughput DL',\n",
    "    'Avg Bearer TP UL (kbps)': 'Avg Throughput UL'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Aggregate Metrics\n",
    "aggregated_metrics = df.groupby('MSISDN/Number').agg({\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'mean',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'mean',\n",
    "    'Avg RTT DL (ms)': 'mean',\n",
    "    'Avg RTT UL (ms)': 'mean',\n",
    "    'Avg Bearer TP DL (kbps)': 'mean',\n",
    "    'Avg Bearer TP UL (kbps)': 'mean',\n",
    "    'Handset Type': 'first'  # Assuming a single handset type per user\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "aggregated_metrics.rename(columns={\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'Avg TCP DL Retransmission',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'Avg TCP UL Retransmission',\n",
    "    'Avg RTT DL (ms)': 'Avg RTT DL',\n",
    "    'Avg RTT UL (ms)': 'Avg RTT UL',\n",
    "    'Avg Bearer TP DL (kbps)': 'Avg Throughput DL',\n",
    "    'Avg Bearer TP UL (kbps)': 'Avg Throughput UL'\n",
    "}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSISDN/Number', 'Avg TCP DL Retransmission',\n",
      "       'Avg TCP UL Retransmission', 'Avg RTT DL', 'Avg RTT UL',\n",
      "       'Avg Throughput DL', 'Avg Throughput UL', 'Handset Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(aggregated_metrics.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Engagement and Experience Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Avg Throughput DL' and 'Avg Throughput UL' are in kbps, you can add them to get total traffic\n",
    "aggregated_metrics['Total Traffic'] = aggregated_metrics['Avg Throughput DL'] + aggregated_metrics['Avg Throughput UL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagement Cluster Centers:\n",
      " [[-7.02421533e-02  1.82629432e+00 -4.71266588e-03]\n",
      " [ 1.44567817e-02 -3.79256805e-01 -3.95350593e-02]\n",
      " [-2.31760126e-02  2.48497102e+00  2.25510628e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you are working with available metrics for experience and engagement clustering\n",
    "# Engagement clustering\n",
    "engagement_features = aggregated_metrics[['Avg RTT DL', 'Avg Throughput DL', 'Avg TCP DL Retransmission']]\n",
    "scaler = StandardScaler()\n",
    "normalized_engagement_features = scaler.fit_transform(engagement_features)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "engagement_kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "engagement_clusters = engagement_kmeans.fit(normalized_engagement_features)\n",
    "\n",
    "# Print the cluster centers for engagement clustering\n",
    "print(\"Engagement Cluster Centers:\\n\", engagement_kmeans.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience Cluster Centers:\n",
      " [[-7.02421533e-02  1.82629432e+00 -4.71266588e-03]\n",
      " [ 1.44567817e-02 -3.79256805e-01 -3.95350593e-02]\n",
      " [-2.31760126e-02  2.48497102e+00  2.25510628e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Experience clustering (using the same features for example)\n",
    "experience_features = aggregated_metrics[['Avg RTT DL', 'Avg Throughput DL', 'Avg TCP DL Retransmission']]\n",
    "normalized_experience_features = scaler.fit_transform(experience_features)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "experience_kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "experience_clusters = experience_kmeans.fit(normalized_experience_features)\n",
    "\n",
    "# Print the cluster centers for experience clustering\n",
    "print(\"Experience Cluster Centers:\\n\", experience_kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Engagement Score  Experience Score\n",
      "0      2.080991e+07      2.080991e+07\n",
      "1      2.080991e+07      2.080991e+07\n",
      "2      2.080991e+07      2.080991e+07\n",
      "3      1.087203e+03      1.087491e+03\n",
      "4      1.507979e+07      1.507979e+07\n"
     ]
    }
   ],
   "source": [
    "# Assuming we are using engagement centroids for one cluster (e.g., the first cluster)\n",
    "engagement_centroid = engagement_kmeans.cluster_centers_[0]  # First cluster centroid\n",
    "experience_centroid = experience_kmeans.cluster_centers_[0]  # First cluster centroid\n",
    "\n",
    "# Calculate the Euclidean distance for each user from the centroids\n",
    "aggregated_metrics['Engagement Score'] = np.linalg.norm(aggregated_metrics[['Avg RTT DL', 'Avg Throughput DL', 'Avg TCP DL Retransmission']].values - engagement_centroid, axis=1)\n",
    "aggregated_metrics['Experience Score'] = np.linalg.norm(aggregated_metrics[['Avg TCP DL Retransmission', 'Avg RTT DL', 'Avg Throughput DL']].values - experience_centroid, axis=1)\n",
    "\n",
    "# View the scores\n",
    "print(aggregated_metrics[['Engagement Score', 'Experience Score']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satisfaction Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MSISDN/Number  Satisfaction Score\n",
      "85785   3.369858e+10        4.289488e+09\n",
      "32273   3.365871e+10        4.288060e+09\n",
      "58026   3.366491e+10        4.268432e+09\n",
      "31942   3.365863e+10        4.254644e+09\n",
      "62049   3.366613e+10        4.211189e+09\n",
      "70079   3.366877e+10        4.166591e+09\n",
      "43629   3.366131e+10        4.131046e+09\n",
      "48341   3.366240e+10        4.117753e+09\n",
      "64113   3.366682e+10        3.968072e+09\n",
      "98211   3.376264e+10        3.785295e+09\n"
     ]
    }
   ],
   "source": [
    "# Calculate the satisfaction score as the average of engagement and experience scores\n",
    "aggregated_metrics['Satisfaction Score'] = (aggregated_metrics['Engagement Score'] + aggregated_metrics['Experience Score']) / 2\n",
    "\n",
    "# Sort by satisfaction score and get top 10 satisfied customers\n",
    "top_10_satisfied_customers = aggregated_metrics[['MSISDN/Number', 'Satisfaction Score']].sort_values(by='Satisfaction Score', ascending=False).head(10)\n",
    "print(top_10_satisfied_customers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Satisfaction Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.9998991464740772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Define the features (engagement and experience scores) and target (satisfaction score)\n",
    "X = aggregated_metrics[['Engagement Score', 'Experience Score']]\n",
    "y = aggregated_metrics['Satisfaction Score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Random Forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict satisfaction scores\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance (e.g., using R^2 score)\n",
    "print(f'R^2 score: {r2_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Satisfaction Score  Engagement Score  Experience Score\n",
      "Satisfaction Cluster                                                        \n",
      "0                           1.682820e+07      1.682820e+07      1.682820e+07\n",
      "1                           2.224330e+09      2.224330e+09      2.224330e+09\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Means clustering (k=2) on the engagement and experience scores\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Combine engagement and experience scores for clustering\n",
    "X_cluster = aggregated_metrics[['Engagement Score', 'Experience Score']]\n",
    "\n",
    "# Apply K-Means clustering (k=2)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "aggregated_metrics['Satisfaction Cluster'] = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "# Aggregate average satisfaction and experience scores per cluster\n",
    "cluster_avg_scores = aggregated_metrics.groupby('Satisfaction Cluster')[['Satisfaction Score', 'Engagement Score', 'Experience Score']].mean()\n",
    "print(cluster_avg_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Export to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(33601001722.0, 20809914.27513532, 20809914.34066387, 20809914.307899594), (33601001754.0, 20809914.27512755, 20809914.340658523, 20809914.307893038), (33601002511.0, 20809914.27539584, 20809914.340919543, 20809914.30815769), (33601007832.0, 1087.2032712623193, 1087.4906853526488, 1087.346978307484), (33601008617.0, 15079785.663573071, 15079785.731547737, 15079785.697560403), (33601010682.0, 10406337.819069417, 10406337.885248734, 10406337.852159075), (33601011634.0, 10454116.207657216, 10454116.276771015, 10454116.242214115), (33601011959.0, 796.8552946171471, 798.476335794216, 797.6658152056816), (33601014694.0, 20809914.27537693, 20809914.340899795, 20809914.308138363), (33601020306.0, 20809914.275269944, 20809914.34080056, 20809914.308035254)]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# Create a connection string for PostgreSQL\n",
    "db_connection_str = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "engine = create_engine(db_connection_str)\n",
    "\n",
    "# Save the final table to PostgreSQL (replace 'user_scores' with your table name)\n",
    "aggregated_metrics[['MSISDN/Number', 'Engagement Score', 'Experience Score', 'Satisfaction Score']].to_sql('user_scores', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Query to check if the data is inserted correctly\n",
    "with engine.connect() as connection:\n",
    "    query = text('SELECT * FROM user_scores LIMIT 10;')  # Wrap the query with text()\n",
    "    result = connection.execute(query).fetchall()\n",
    "\n",
    "# Display result\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
